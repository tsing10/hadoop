		
		day1：hadoop环境搭建

准备：

0、安装MobaXterm_Setup_9.2：用于windows以ssh方式连接linux系统

	ip：192.168.43.180
	
	有了连接方式，就不需要设置虚拟机与宿主机之间的共享
	
1、安装虚拟机VMware_workstation_full_12.5.2：用于安装多个linux系统

****************已经废弃，原因是centos门槛太高，学习进度缓慢*******************
2、安装centos7 CentOS-7-x86_64-DVD-1511

centos01 
	ip：192.168.255.128
	
	为hadoop用户增加管理员权限时出错：
	
	问题 1、下面语句不管用
	
	$ sudo adduser hadoop sudo  #为hadoop用户增加管理员权限
	
解决方案：手动修改visudo

	1、root用户下执行命令：visudo

	2、在root  ALL=(ALL)       NOPASSWD:ALL 
	
	下面添加一行：hadoop  ALL=(ALL)       NOPASSWD:ALL

	保存即可
*******************************************************************************

2、安装ubuntu ubuntu-16.04-desktop-amd64
	虚拟机安装过程简单，需要注意的有
	1、网络适配器模式：仅主机模式，原因未知，会出现无法上网的毛病
	2、安装的时候不要联网，否则要下载许多其他软件，太慢了
	3、用户名/密码 tsing01/123
	
	安装完成后，进行以下操作：
	$ sudo apt upgrade //升级
	$ sudo apt update //更新 这两个顺序不可颠倒
	$ sudo apt install vim //安装vim
	
	ip: 192.168.72.130
	
	ubuntu16设置静态IP：
	1、设置ip：vim 编辑interface
	$ sudo vim /etc/network/interfaces
	
	追加几行代码：
# the primary network interface
auto ens33 //默认网卡
iface ens33 inet static //静态网络
address 192.168.72.130 //ip地址
netmask 255.255.255.0 //子网掩码
gateway 192.168.1.1 //网关
	2、设置DNS：vim编辑
	$ sudo vi /etc/resolvconf/resolv.conf.d/base
	追加几行代码：
nameserver 8.8.8.8
nameserver 8.8.4.4

	常用DNS有：
	googleDNS： 8.8.8.8   			8.8.4.4
	114DNS：	114.114.114.114 	114.114.115.115
	阿里DNS：	223.5.5.5 			223.6.6.6
	中科大的DNS	
	202.38.64.1
202.112.20.131
202.141.160.95
202.141.160.99
202.141.176.95
202.141.176.99
	3、重启网络服务
	
	/etc/init.d/networking restart
	如果无效就重启系统
	*注意 自从ubuntu15.04网络管理工具废弃了nm-tool，改为nmcli
	nmcli dev show //查看mac ip DNS



ubuntu搭建hadoop教程地址：https://www.cnblogs.com/87hbteo/p/7606012.html

3、创建hadoop用户：
	$ sudo useradd -m hadoop -s /bin/bash  #创建hadoop用户，并使用/bin/bash作为shell
	$ sudo passwd hadoop                   #为hadoop用户设置密码，之后需要连续输入两次密码
	$ sudo adduser hadoop sudo             #为hadoop用户增加管理员权限
	$ su - hadoop                          #切换当前用户为用户hadoop
	$ sudo apt-get update                  #更新hadoop用户的apt,方便后面的安装

4、安装java
	默认安装了openjdk，因为openjdk是jdk的精简版本，阉割了许多功能，还是需要安装jdk	
	查看是否安装openjdk
	$ java -version 
	卸载openjdk
	$ sudo apt autoremove openjdk* 
	
	******************放弃 原因：速度慢 时间长********************
	添加ppa源
	$ sudo add-apt-repository ppa:webupd8team/java 
	更新源数据库
	$ sudo apt-get update
	安装 Oracle Java 8
	$ sudo apt-get install oracle-java8-installer
	查看java版本
	$ java -version
	设置java环境变量
	$ sudo apt-get install oracle-java8-set-default
	***************************************************************
	
	下载jdk-8u111-linux-x64.tar 放到Downlaods目录下
	$ cd ~/Downlaods					
	解压tar包
	$ sudo tar -zxvf jdk-8u111-linux-x64.tar.gz -C /usr/lib
	进入目录
	$ cd /usr/lib
	重命名为java，如果jvm不存在， sudo mkdir jvm
	$ sudo mv jdk1.8.0_111 jvm/java
	备份配置文件，防止改动失误
	$ cp  ~/.bashrc ~/.bashrc.copy
	vim编辑配置文件
	$ vim ~/.bashrc
	在.bashrc文档尾部追加四行代码
export JAVA_HOME=/usr/lib/jvm/java
export JRE_HOME=${JAVA_HOME}/jre
export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib
export PATH=${JAVA_HOME}/bin:$PATH
	如果懒得手动输入代码，可以选择 
	1）重定向
	将代码写入一个文件 a
	$ cat a >> ~/.bashrc
	2）安装vim-gnome
	$ sudo apt install vim-gnome
	在vim界面输入 "+p 完成从系统粘贴板到文档的复制
	附加：
	"+y ：复制到粘贴板
	
	使配置文件立即生效
	$ source ~/.bashrc
	验证安装成功？
	$ java -version
	
5、安装hadoop
	先下载hadoop-2.6.0.tar.gz，链接如下: 
	http://mirrors.hust.edu.cn/apache/hadoop/common/

	下面进行安装：

	$ sudo tar -zxvf  hadoop-2.6.0.tar.gz -C /usr/local    #解压到/usr/local目录下
	$ cd /usr/local
	$ sudo mv  hadoop-2.6.0    hadoop                      #重命名为hadoop
	$ sudo chown -R hadoop ./hadoop                        #修改文件权限

	给hadoop配置环境变量，将下面代码添加到.bashrc文件:

	export HADOOP_HOME=/usr/local/hadoop
	export CLASSPATH=$($HADOOP_HOME/bin/hadoop classpath):$CLASSPATH
	export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
	export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
	
6、伪分布式配置

	Hadoop 可以在单节点上以伪分布式的方式运行，Hadoop 进程以分离的 Java 进程来运行，节点既作为 NameNode 也作为 DataNode，同时，读取的是 HDFS 中的文件。Hadoop 的配置文件位于 /usr/local/hadoop/etc/hadoop/ 中，伪分布式需要修改2个配置文件 core-site.xml 和 hdfs-site.xml 。Hadoop的配置文件是 xml 格式，每个配置以声明 property 的 name 和 value 的方式来实现。首先将jdk1.7的路径添（export JAVA_HOME=/usr/lib/jvm/java ）加到hadoop-env.sh文件 

	接下来修改core-site.xml文件：

	<configuration>
			<property>
				 <name>hadoop.tmp.dir</name>
				 <value>file:/usr/local/hadoop/tmp</value>
				 <description>Abase for other temporary directories.</description>
			</property>
			<property>
				 <name>fs.defaultFS</name>
				 <value>hdfs://localhost:9000</value>
			</property>
	</configuration>


	接下来修改配置文件 hdfs-site.xml

	<configuration>
			<property>
				 <name>dfs.replication</name>
				 <value>1</value>
			</property>
			<property>
				 <name>dfs.namenode.name.dir</name>
				 <value>file:/usr/local/hadoop/tmp/dfs/name</value>
			</property>
			<property>
				 <name>dfs.datanode.data.dir</name>
				 <value>file:/usr/local/hadoop/tmp/dfs/data</value>
			</property>
	</configuration>

	Hadoop 的运行方式是由配置文件决定的（运行 Hadoop 时会读取配置文件），因此如果需要从伪分布式模式切换回非分布式模式，需要删除 core-site.xml 中的配置项。此外，伪分布式虽然只需要配置 fs.defaultFS 和 dfs.replication 就可以运行（可参考官方教程），不过若没有配置 hadoop.tmp.dir 参数，则默认使用的临时目录为 /tmp/hadoo-hadoop，而这个目录在重启时有可能被系统清理掉，导致必须重新执行 format 才行。所以我们进行了设置，同时也指定 dfs.namenode.name.dir 和 dfs.datanode.data.dir，否则在接下来的步骤中可能会出错。

	配置完成后，执行 NameNode 的格式化

	$ ./bin/hdfs namenode -format

	启动namenode和datanode进程，并查看启动结果

	$ ./sbin/start-dfs.sh
	$ jps

	启动完成后，可以通过命令 jps 来判断是否成功启动，若成功启动则会列出如下进程: “NameNode”、”DataNode” 和 “SecondaryNameNode” 

7、克隆虚拟机
	将配置好的虚拟机文件拷贝2份，然后虚拟机中文件 -> 打开 选择拷贝的文件；在打开备份的虚拟机时会弹出对话框，选择复制就好。
	ubuntu00作为主机00 
	ubuntu01作为副机01 
	ubuntu02作为副机02
	
8、Linux多台机器配置ssh免登录
	1.安装ssh.  sudo apt-get install ssh. 安装完成后会在~目录（当前用户主目录，即这里的/home/xuhui）下产生一个隐藏文件夹.ssh（ls -a 可以查看隐藏文件）。如果没有这个文件，自己新建即可（mkdir .ssh）.

	2.进入.ssh目录下面，在每台机器上执行：ssh-keygen -t  rsa  之后一路回车，产生密钥；

	3.完成第二步后会产生两个文件：

	id-rsa     #私钥
	id-rsa.pub   #公钥

	4.在第一台机器的目录.ssh下执行命令，$ cat  id-rsa.pub >> authorized_keys；此后.ssh下面会出现authorized_keys文件。

	5.然后将第一台机器的.ssh目录下面的authorized_keys文件拷贝到第二台计算机的.ssh目录下，如：scp authorized_keys xuhui@192.168.72.101:~/.ssh/

	6.再转到第二台机器的.ssh目录下，会发现刚刚传输过来的文件-authorized_keys，然后执行命令，将第二台计算机的公钥也加进来，如：cat id-rsa.pub >> authorized_keys.

	7.将第二台计算机新生成的authorized_keys传输第三台计算机，将第三台计算机的公钥-id-rsa.pub添加到从第二台计算机传过来的authorized_keys里面。

	8.依次类推，直至最后一台计算机。

	9.在最后一台计算机执行完添加后，生成的authorized_keys文件就包含所有计算机的公钥，如果以后还有机器加进来，可以直接添加到文件-authorized_keys。最后，将最后生成的authorized_keys复制到每一台计算机的.ssh目录下，覆盖掉之前的authorized_keys。

	10.完沉第九步后，就可以在任意一台计算机上，免密码ssh登录到其他计算了。

day2：
	




